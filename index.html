<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Jürgen Mathes – Projects & Publications</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="canonical" href="https://juergenmathes.github.io/juergenmathes/" />
  <link rel="icon" href="https://github.com/juergenmathes.png?size=64" />

  <!-- Open Graph -->
  <meta property="og:title" content="Jürgen Mathes – Projects & Publications" />
  <meta property="og:description" content="Research Engineer bridging state-of-the-art AI and real-world robotics. Explore projects, publications, and patents." />
  <meta property="og:url" content="https://juergenmathes.github.io/juergenmathes/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Jürgen Mathes" />
  <meta property="og:image" content="https://juergenmathes.github.io/juergenmathes/artifacts/2023_wayhome_01.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Jürgen Mathes – Projects & Publications" />
  <meta name="twitter:description" content="Research Engineer bridging state-of-the-art AI and real-world robotics. Explore projects, publications, and patents." />
  <meta name="twitter:image" content="https://juergenmathes.github.io/juergenmathes/artifacts/2023_wayhome_01.png" />

  <!-- Schema.org Person -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Jürgen Mathes",
    "url": "https://juergenmathes.github.io/juergenmathes/",
    "jobTitle": "Research Engineer – Planning & Robotics",
    "image": "https://github.com/juergenmathes.png?size=400",
    "sameAs": [
      "https://github.com/juergenmathes",
      "https://www.linkedin.com/in/juergen-mathes-44b389131/",
      "https://scholar.google.com/citations?user=6qs34YkAAAAJ"
    ]
  }
  </script>

  <style>
    :root{
      --bg:#fafafa; --fg:#222; --muted:#666; --card:#fff; --border:#eee; --chip:#f1f1f1; --brand:#0a66c2;
    }
    * { box-sizing: border-box; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, sans-serif; margin: 0; background: var(--bg); color: var(--fg); }
    a { color: var(--fg); }

    /* Layout */
    .container{ max-width: 1100px; margin: 0 auto; padding: 2rem; }
    header { display:flex; align-items:center; gap:1.25rem; padding-top: 1rem; padding-bottom: 1rem; }
    header img { width:128px; height:128px; border-radius:50%; object-fit:cover; }
    .title-wrap h1{ margin:0; font-size:1.8rem; }
    .subtitle{ margin:0.25rem 0 0; color:var(--muted); }
    .tagline{ margin-top:0.4rem; font-weight:600; }

    nav { margin-top:0.5rem; }
    .nav a{ display:inline-block; margin-right:0.6rem; padding:0.35rem 0.7rem; border:1px solid #ccc; border-radius:999px; font-size:0.9rem; text-decoration:none; }
    .nav a:hover{ background:#f5f5f5; }

    .chips{ display:flex; flex-wrap:wrap; gap:0.5rem; margin-top:0.75rem; }
    .chip{ background:var(--chip); border:1px solid var(--border); padding:0.25rem 0.55rem; border-radius:999px; font-size:0.85rem; }
    .chip a{ text-decoration:none; }

    .title-link{ text-decoration:none; color:inherit; }
    .title-link:hover h3{ text-decoration:underline; }
    .card a{ display:block; }

    section{ margin-top: 1.5rem; }
    .section-card{ background:var(--card); border:1px solid var(--border); border-radius:12px; padding:1rem 1.25rem; }

    h2{ margin:0 0 0.75rem; font-size:1.25rem; }

    /* Optional section heading variants; toggle by setting the class on <body> */
    body.heading-style-divider .section-heading {
      font-size: 1.4rem;
      font-weight: 600;
      margin: 1.5rem 0 1rem;
      padding-bottom: 0.4rem;
      border-bottom: 1px solid var(--border);
    }
    body.heading-style-highlight .section-heading {
      font-size: 1.3rem;
      font-weight: 600;
      margin: 1.5rem 0 1.25rem;
      padding: 0.4rem 0.8rem;
      background: #f9f9f9;
      border-radius: 6px;
    }
    body.heading-style-label .section-heading {
      font-size: 0.95rem;
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 1.5px;
      color: var(--muted);
      margin: 1.5rem 0 1rem;
    }
    p  { margin-top: 0; line-height: 1.6; }
    ul { margin: 0.25rem 0 0.75rem 1.2rem; }

    /* Shared project styles from your original */
    .project-split{
      display:grid; grid-template-columns:1fr 1fr; gap:2rem; align-items:start;
      background:#fff; padding:1.5rem; border-radius:12px; box-shadow:0 2px 8px rgba(0,0,0,0.06);
      margin-bottom:2rem; border:1px solid var(--border);
    }
    .split-left h3{ margin-top:0; }
    .btn{
      display:inline-block; margin-top:1rem; padding:0.5rem 0.9rem; border:1px solid #ccc;
      border-radius:8px; text-decoration:none; color:#222; font-weight:600;
    }
    .btn:hover{ background:#f5f5f5; }

    .split-right{ display:grid; grid-template-columns:1fr 1fr; gap:1rem; }
    .card{ margin:0; border:1px solid #eee; border-radius:8px; overflow:hidden; background:#fff; text-align:center; }
    .card img { width: 100%; height: 220px; object-fit: contain; display: block; }
    .same-width { width: 100%; height: auto; object-fit: contain; }
    .card figcaption{ padding:0.5rem 0.75rem; font-size:0.9rem; color:#555; border-top:1px solid #eee; }
    .card figcaption a{ color:inherit; text-decoration:none; }
    .card figcaption a:hover{ text-decoration:underline; }
    .gif-img{ width:auto; max-width:100%; max-height:250px; display:inline-block; }
    .media-grid{ display:grid; gap:1rem; margin-top:1rem; }
    .media-grid.two-up{ grid-template-columns:1fr 1fr; }

    /* Make video thumbs use the full right column width for marked sections only */
    .project-split.media-right-wide .split-right{
      grid-template-columns: 1fr;
      gap: 1.25rem;
    }

    .project-split.media-right-wide .card{
      border: 0;
      border-radius: 12px;
      overflow: hidden;
      text-align: left;
    }

    .project-split.media-right-wide .yt-link,
    .project-split.media-right-wide .yt-thumb{
      display: block;
      width: 100%;
    }

    .project-split.media-right-wide .yt-thumb{
      height: auto;
      aspect-ratio: 16 / 9;
      object-fit: cover;
    }

    /* WayHome: natural dimensions */
    .project-split[aria-labelledby="wayhome-title"] .yt-thumb{
      height: auto;
      aspect-ratio: auto;
      object-fit: contain;
      background: transparent;
    }

    .project-split[aria-labelledby="scaling-title"] .yt-thumb{
      height: auto;
      aspect-ratio: auto;
      object-fit: contain;
      background: transparent;
    }

    .project-split[aria-labelledby="s3dpps-title"] .yt-thumb{
      height: auto;
      aspect-ratio: auto;
      object-fit: contain;
      background: transparent;
    }

    .project-split.media-right-wide .yt-play{
      padding: 14px 18px;
      font-weight: 700;
    }

    .yt-link{ position:relative; display:block; text-decoration:none; color:inherit; }
    .yt-thumb{ display:block; width:100%; height:auto; }
    .yt-play{ position:absolute; left:50%; top:50%; transform:translate(-50%,-50%);
      background:rgba(0,0,0,0.6); border-radius:999px; padding:12px 16px; font-weight:700; color:#fff; line-height:1; user-select:none; }
    .yt-link:hover .yt-play{ background:rgba(0,0,0,0.75); }

    @media (max-width:900px){
      .project-split{ grid-template-columns:1fr; }
      .split-right{ grid-template-columns:1fr; }
      header { align-items:flex-start; }
    }

    footer{ color:var(--muted); font-size:0.9rem; margin-top:2rem; padding-bottom:2rem; }
  </style>
</head>
<body class="heading-style-divider">
  <div class="container">
    <!-- Personal hero -->
    <header>
      <img src="artifacts/1593018480037.jpeg" alt="Portrait of Jürgen Mathes" loading="eager" />
      <div class="title-wrap">
        <h1 id="top">Jürgen Mathes</h1>
        <p class="subtitle">Stuttgart, Germany • English / German / Español</p>
        <p class="tagline">Research Engineer bridging state-of-the-art AI and real-world robotics.</p>
        <nav class="nav" aria-label="Primary">
          <a href="#about">About</a>
          <a href="#projects">Independent Projects</a>
          <a href="#publications">Publications</a>
          <a href="#talks">AI Papers Explained</a>
          <a href="#patents">Patents</a>
          <a href="#contact">Contact</a>
        </nav>
        <div class="chips" aria-label="Quick links">
          <span class="chip"><a href="https://www.linkedin.com/in/juergen-mathes-44b389131/" target="_blank" rel="noopener">LinkedIn</a></span>
          <span class="chip"><a href="https://scholar.google.com/citations?user=6qs34YkAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener">Google Scholar</a></span>
          <!-- Optional: add your CV pdf to /artifacts and uncomment: -->
          <!-- <span class="chip"><a href="artifacts/Juergen_Mathes_CV.pdf" target="_blank" rel="noopener">Download CV</a></span> -->
        </div>
      </div>
    </header>

  <section id="about" aria-labelledby="about-title">
    <h2 id="about-title" class="section-heading">About</h2>
    <div class="section-card">
      <p>
        I’m a Research Engineer specializing in <strong>AI-based planning and robotics</strong>, building models,
        simulation pipelines, and decision-making systems that translate cutting-edge research into
        <em>real vehicles</em>. My current focus spans <strong>scalable planning algorithms</strong>, the
        <strong>integration of learning-based and model-based methods</strong> for reliable decisions,
        <strong>simulation-to-reality transfer</strong> for safe, efficient deployment, and
        <strong>large-scale training pipelines</strong> with rigorous, data-driven evaluation.
      </p>
    </div>
  </section>

  

    <!-- Projects header -->
    <section id="projects" aria-labelledby="proj-title">
      <h2 id="proj-title" class="section-heading">Independent Projects</h2>
    </section>

    <!-- Tiny PathFormer -->
    <section class="project-split" aria-labelledby="tiny-pathformer-title">
      <div class="split-left">
        <h3 id="tiny-pathformer-title">Tiny PathFormer</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">September 2025</p>
        <p>Lightweight toy project for learning path planning with an autoregressive policy. Trains on synthetic grid mazes and visualizes trajectories.</p>
        <a class="btn" href="https://github.com/juergenmathes/tiny-pathformer" target="_blank" rel="noopener">View on GitHub</a>
      </div>
      <div class="split-right">
        <figure class="card">
          <img class="gif-img" src="https://github.com/juergenmathes/tiny-pathformer/raw/main/videos/best_ep40_ok.gif" alt="Tiny PathFormer demo ep40" loading="lazy">
          <figcaption>Autoregressive rollout (ep40)</figcaption>
        </figure>
        <figure class="card">
          <img class="gif-img" src="https://github.com/juergenmathes/tiny-pathformer/raw/main/videos/best_ep56_ok.gif" alt="Tiny PathFormer demo ep56" loading="lazy">
          <figcaption>Autoregressive rollout (ep56)</figcaption>
        </figure>
      </div>
    </section>

    <!-- Equilibrium Matching 2D -->
    <section class="project-split" aria-labelledby="eqm-title">
      <div class="split-left">
        <h3 id="eqm-title">Equilibrium Matching 2D</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">August 2025</p>
        <p>
          Explored equilibrium matching as a time-independent alternative to diffusion and flow matching for controlled trajectory generation.
          Demonstrated how static vector fields can synthesize structured paths from noise and provided a tutorial-style walkthrough with reproducible scripts. The visualizations highlight how the EqM field stabilizes across epochs to converge on consistent trajectories.
        </p>
        <a class="btn" href="https://github.com/juergenmathes/EquilibriumMatching-2D" target="_blank" rel="noopener">View on GitHub</a>
      </div>
      <div class="split-right">
        <figure class="card">
          <a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_00.mp4" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_00.gif" alt="Equilibrium Matching trajectory sample 00" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_00.mp4" target="_blank" rel="noopener">Inference – sample 00 (mp4)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_01.mp4" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_01.gif" alt="Equilibrium Matching trajectory sample 01" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_01.mp4" target="_blank" rel="noopener">Inference – sample 01 (mp4)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_02.mp4" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_02.gif" alt="Equilibrium Matching trajectory sample 02" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/traj_sample_02.mp4" target="_blank" rel="noopener">Inference – sample 02 (mp4)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/vector_field_quiver_and_stream_together.gif" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/vector_field_quiver_and_stream_together.gif" alt="Equilibrium Matching vector field quiver and stream visualization" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/EquilibriumMatching-2D/raw/main/outputs_eqm/videos/vector_field_quiver_and_stream_together.gif" target="_blank" rel="noopener">Vector field quiver + stream</a></figcaption>
        </figure>
      </div>
    </section>

    <!-- LineDiffusion / DiffuTraj -->
    <section class="project-split" aria-labelledby="linediff-title">
      <div class="split-left">
        <h3 id="linediff-title">LineDiffusion (DiffuTraj)</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">June 2025</p>
        <p>Developed a minimal denoising diffusion model for constrained 2D trajectories, enforcing fixed endpoints and visualized reverse diffusion with MP4/GIF animations; provided a reproducible baseline that demonstrates how diffusion can reconstruct structured motion under constraints.</p>
        <a class="btn" href="https://github.com/juergenmathes/LineDiffusion" target="_blank" rel="noopener">View on GitHub</a>
      </div>
      <div class="split-right">
        <figure class="card">
          <a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_00.gif" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_00.gif" alt="LineDiffusion trajectory sample 00" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_00.gif" target="_blank" rel="noopener">Reverse diffusion (sample 00)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_01.gif" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_01.gif" alt="LineDiffusion trajectory sample 01" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_01.gif" target="_blank" rel="noopener">Reverse diffusion (sample 01)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_02.gif" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_02.gif" alt="LineDiffusion trajectory sample 02" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_02.gif" target="_blank" rel="noopener">Reverse diffusion (sample 02)</a></figcaption>
        </figure>
        <figure class="card">
          <a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_03.gif" target="_blank" rel="noopener">
            <img class="gif-img" src="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_03.gif" alt="LineDiffusion trajectory sample 03" loading="lazy">
          </a>
          <figcaption><a href="https://github.com/juergenmathes/LineDiffusion/raw/main/outputs/videos/traj_sample_03.gif" target="_blank" rel="noopener">Reverse diffusion (sample 03)</a></figcaption>
        </figure>
      </div>
    </section>

    <!-- S3DPPS Project (local artifacts) -->
    <section class="project-split media-right-wide" aria-labelledby="s3dpps-title">
      <div class="split-left">
        <h3 id="s3dpps-title">S3DPPS (3D Pick and Place)</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">May 2025</p>
        <p>
          Developed S3DPPS, a two-stage transformer pipeline for 3D bounding box prediction from segmented point clouds,
          improving corner accuracy by ~20% over single-object baselines and enabling real-time (&lt;50 ms) multi-object
          pick-and-place; integrated MLflow tracking and 3D visualizations for reproducibility, with extensibility to
          open-world detectors, multimodal fusion, and advanced 3D encoders.
        </p>
        <a class="btn" href="https://github.com/juergenmathes/s3dpps" target="_blank" rel="noopener">View on GitHub</a>
      </div>

      <div class="split-right">
        <figure class="card" style="grid-column: 1 / -1; border:0; border-radius:12px; overflow:hidden;">
          <a href="artifacts/s3dpps_streamlit_orig.gif" target="_blank" rel="noopener">
            <img class="yt-thumb" src="artifacts/s3dpps_streamlit_360.gif" alt="S3DPPS interactive 3D point cloud visualization" loading="lazy">
          </a>
          <figcaption style="text-align:center;">3D point cloud visualization</figcaption>
        </figure>

        <figure class="card" style="grid-column: 1 / -1;">
          <a href="artifacts/s3dpps_3dpreds_orig.gif" target="_blank" rel="noopener">
            <img class="yt-thumb" src="artifacts/s3dpps_3dpreds_360.gif" alt="S3DPPS final 3D bounding box predictions" loading="lazy">
          </a>
          <figcaption style="text-align:center;">Final 3D bounding box predictions</figcaption>
        </figure>
      </div>
    </section>

    <!-- Talks & Paper Explainers -->
    <section id="talks" aria-labelledby="talks-title">
      <h2 id="talks-title" class="section-heading">AI Papers Explained</h2>
    </section>

    <!-- Video Section: M3DETR (External Presentation) -->
    <section class="project-split media-right-wide" aria-labelledby="m3detr-title">
      <div class="split-left">
        <h3 id="m3detr-title">M3DETR: Multi-representation Multi-scale Transformers for 3D Object Detection</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">December 2022</p>
        <p>
          Combines raw, voxel, and bird’s-eye-view point cloud representations with multi-scale feature pyramids.
          M3DETR unifies multiple representations and scales while modeling relationships between point clouds using transformers.
          Achieves state-of-the-art results on KITTI and Waymo benchmarks.
          <br><br>
          <strong>Sources:</strong>
          <a href="https://arxiv.org/abs/2104.11896" target="_blank" rel="noopener">[2104.11896]</a>,
          <a href="https://arxiv.org/abs/1912.13192" target="_blank" rel="noopener">[1912.13192]</a>
          <br>
          <strong>Tags:</strong> #transformers #objectdetection #pointclouds
        </p>
      </div>
      <div class="split-right">
        <figure class="card">
          <a class="yt-link" href="https://www.youtube.com/watch?v=SQrVUqhrvII" target="_blank" rel="noopener" aria-label="Watch M3DETR presentation on YouTube">
            <img class="yt-thumb" src="https://img.youtube.com/vi/SQrVUqhrvII/hqdefault.jpg" alt="M3DETR video thumbnail" loading="lazy">
            <span class="yt-play">▶</span>
          </a>
        </figure>
      </div>
    </section>

    <!-- Video Section: Scene Transformer (External Presentation) -->
    <section class="project-split media-right-wide" aria-labelledby="scene-transformer-title">
      <div class="split-left">
        <h3 id="scene-transformer-title">Scene Transformer: Unified Architecture for Multi-Agent Trajectory Prediction</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">December 2022</p>
        <p>
          Predicts the motion of all agents jointly, producing consistent futures that account for interactions.
          Inspired by language models with masking strategies for flexible conditioning.
          Achieves state-of-the-art results on popular autonomous driving datasets.
          <br><br>
          <strong>Source:</strong>
          <a href="https://arxiv.org/abs/2106.08417" target="_blank" rel="noopener">[2106.08417]</a>
          <br>
          <strong>Tags:</strong> #transformers #prediction #planning
        </p>
      </div>
      <div class="split-right">
        <figure class="card">
          <a class="yt-link" href="https://www.youtube.com/watch?v=YJKo_F3uUwU" target="_blank" rel="noopener" aria-label="Watch Scene Transformer presentation on YouTube">
            <img class="yt-thumb" src="https://img.youtube.com/vi/YJKo_F3uUwU/hqdefault.jpg" alt="Scene Transformer video thumbnail" loading="lazy">
            <span class="yt-play">▶</span>
          </a>
        </figure>
      </div>
    </section>

    <!-- Video Section: End-to-End Video Object Detection (External Presentation) -->
    <section class="project-split media-right-wide" aria-labelledby="e2e-vidod-title">
      <div class="split-left">
        <h3 id="e2e-vidod-title">End-to-End Video Object Detection with Spatial-Temporal Transformers</h3>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">December 2022</p>
        <p>
          Builds on DETR by introducing Deformable DETR to improve convergence and small-object detection.
          Uses spatial-temporal transformers for video object detection.
          Achieves higher performance with 10× fewer epochs.
          <br><br>
          <strong>Sources:</strong>
          <a href="https://arxiv.org/abs/2105.10920" target="_blank" rel="noopener">[2105.10920]</a>,
          <a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener">[2005.12872]</a>,
          <a href="https://arxiv.org/abs/2010.04159" target="_blank" rel="noopener">[2010.04159]</a>
          <br>
          <strong>Tags:</strong> #transformers #objectdetection #pointclouds
        </p>
      </div>
      <div class="split-right">
        <figure class="card">
          <a class="yt-link" href="https://www.youtube.com/watch?v=DaULLeq_AAU" target="_blank" rel="noopener" aria-label="Watch End-to-End Object Detection presentation on YouTube">
            <img class="yt-thumb" src="https://img.youtube.com/vi/DaULLeq_AAU/hqdefault.jpg" alt="End-to-End Object Detection thumbnail" loading="lazy">
            <span class="yt-play">▶</span>
          </a>
        </figure>
      </div>
    </section>

    <!-- Publications header -->
    <section id="publications" aria-labelledby="pub-title">
      <h2 id="pub-title" class="section-heading">Publications</h2>
    </section>

    <!-- The WayHome Paper (My Publication) -->
    <section class="project-split media-right-wide" aria-labelledby="wayhome-title">
      <div class="split-left">
        <a class="title-link" href="https://arxiv.org/abs/2310.04232" target="_blank" rel="noopener">
          <h3 id="wayhome-title">The WayHome: Long-term Motion Prediction on Dynamically Scaled Grids</h3>
        </a>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">Oct 2023</p>
        <p>
          We developed a novel motion-forecasting approach for autonomous vehicles that predicts multiple heatmaps per nearby traffic participant at each timestep. A sampling algorithm extracts the most likely coordinates, and a new grid-scaling technique further boosts accuracy. At the time, this was state-of-the-art, reducing miss rates at 3-second horizons while remaining competitive at longer horizons (up to 8s) on the Waymo Motion Challenge.
        </p>
        <a class="btn" href="https://arxiv.org/abs/2310.04232" target="_blank" rel="noopener">Read on arXiv</a>
      </div>
      <div class="split-right">
        <figure class="card">
          <a class="yt-link" href="https://arxiv.org/abs/2310.04232" target="_blank" rel="noopener">
            <img class="yt-thumb" src="artifacts/2023_wayhome_01.png" alt="WayHome predicted heatmaps" loading="lazy">
          </a>
          <figcaption>
            Predicted heatmaps per timestep for surrounding traffic participants.
          </figcaption>
        </figure>
      </div>
    </section>

    <!-- Scaling Planning Paper (My Publication) -->
    <section class="project-split media-right-wide" aria-labelledby="scaling-title">
      <div class="split-left">
        <a class="title-link" href="https://arxiv.org/abs/2305.18942" target="_blank" rel="noopener">
          <h3 id="scaling-title">Scaling Planning for Automated Driving using Simplistic Synthetic Data</h3>
        </a>
        <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">May 2023</p>
        <p>
          We challenge the view that deep learning for driving plans needs massive real-world datasets or highly realistic simulations. With lightweight synthetic roundabout scenarios and behavioural cloning, we achieve reliable and comfortable driving in a real vehicle, while addressing sim-to-real gaps through targeted augmentation and scenario variations.
        </p>
        <a class="btn" href="https://arxiv.org/abs/2305.18942" target="_blank" rel="noopener">Read on arXiv</a>
      </div>
      <div class="split-right">
        <figure class="card">
          <a class="yt-link" href="https://arxiv.org/abs/2305.18942" target="_blank" rel="noopener">
            <img class="yt-thumb" src="artifacts/2023_scaling_imitation_02.png" alt="Scaling Planning artifact 2" loading="lazy">
          </a>
          <figcaption>CNN backbone with waypoints head and auxiliary prediction head.</figcaption>
        </figure>
      </div>
    </section>


    <!-- Experience header -->
<section id="experience" aria-labelledby="exp-title">
  <h2 id="exp-title" class="section-heading">Experience</h2>
</section>

<!-- Bosch Research – Planning & Robotics -->
<section class="project-split media-right-wide" aria-labelledby="bosch-planning-title">
  <div class="split-left">
    <h3 id="bosch-planning-title">Senior Research Engineer – Planning & Robotics</h3>
    <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">
      Bosch Research • Stuttgart, Germany • Jul 2022 – Present
    </p>
    <p>
      Turning state-of-the-art AI planning research into deployed systems on real vehicles, with focus on:
    </p>
    <ul>
      <li>Designing model architectures for planning agents (transformers, world models, tree search).</li>
      <li>Exploring reinforcement learning, imitation learning, and VLM/LLM-based policies.</li>
      <li>Conducting large-scale closed-loop simulation experiments to optimize agent performance.</li>
      <li>Deploying and evaluating trained agents in real vehicles, bridging the sim-to-real gap.</li>
      <li>Building large-scale datasets for training and benchmarking autonomous agents.</li>
      <li>Improving training pipelines and infrastructure to accelerate experimentation and deployment.</li>
    </ul>
  </div>
  <div class="split-right">
    <figure class="card">
      <a class="yt-link"
         href="https://www.youtube.com/watch?v=EMvywc4NY5A"
         target="_blank" rel="noopener">
        <img class="yt-thumb"
             src="https://img.youtube.com/vi/EMvywc4NY5A/hqdefault.jpg"
             alt="YouTube video thumbnail – Bosch AI Research project">
        <span class="yt-play">▶</span>
      </a>
    </figure>

    <figure class="card">
      <a class="yt-link"
         href="https://www.linkedin.com/feed/update/urn:li:activity:7371427689921974272/"
         target="_blank" rel="noopener">
        <img class="yt-thumb"
             src="artifacts/research_cn_car_project.png"
             alt="LinkedIn post thumbnail – Bosch Research update">
        <span class="yt-play">▶</span>
      </a>
    </figure>
  </div>
</section>

<!-- Bosch Research – Multi-Modal Perception -->
<section class="project-split media-right-wide" aria-labelledby="bosch-multimodal-title">
  <div class="split-left">
    <h3 id="bosch-multimodal-title">Senior Machine Learning Engineer – Multi-Modal Perception & Data Labeling</h3>
    <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">
      Bosch • Stuttgart, Germany • Nov 2021 – May 2022
    </p>
    <ul>
      <li>Developed multi-modal transformer-based encoder–decoder architectures for sensor fusion.</li>
      <li>Led a project-wide cloud-based multi-modal labeling initiative (LiDAR, camera, radar).</li>
      <li>Built a data engine to streamline workflows and automate labeling processes.</li>
      <li>Reduced manual labeling costs by 100× through large-scale automation.</li>
      <li>Designed cloud-based infrastructure for efficient dataset generation and management.</li>
    </ul>
  </div>
  <div class="split-right">
    <figure class="card">
      <a class="yt-link"
         href="https://www.bosch-presse.de/pressportal/de/en/bosch-and-mercedes-benz-start-san-jose-pilot-project-for-automated-ride-hailing-service-204032.html"
         target="_blank" rel="noopener">
        <img class="yt-thumb"
             src="https://www.bosch-presse.de/pressportal/de/media/dam_images/pi11064/mercedes_urban_automated_driving_287035x3956-kv_img_w640.jpg"
             alt="Bosch & Mercedes-Benz automated ride-hailing pilot in San José – press image thumbnail">
        <span class="yt-play">▶</span>
      </a>
    </figure>
  </div>
</section>

<!-- Bosch – 3D Perception -->
<section class="project-split media-right-wide" aria-labelledby="bosch-3d-title">
  <div class="split-left">
    <h3 id="bosch-3d-title">Machine Learning Engineer – 3D Perception (LiDAR), Autonomous Driving</h3>
    <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">
      Bosch • Stuttgart, Germany • Apr 2017 – Oct 2021
    </p>
    <ul>
      <li>Developed AI-based perception software for autonomous driving.</li>
      <li>Worked on 3D object detection and semantic segmentation for LiDAR point clouds.</li>
      <li>Adapted architectures and loss functions to improve detection quality.</li>
      <li>Realized runtime optimization and real-time deployment using TensorRT.</li>
      <li>Built large-scale data pipelines and multi-sensor fusion (LiDAR, camera, IMU).</li>
    </ul>
  </div>
  <div class="split-right">
    <figure class="card">
      <a class="yt-link"
         href="https://www.youtube.com/watch?v=C4DPcsnVxHU"
         target="_blank" rel="noopener">
        <img class="yt-thumb"
             src="https://img.youtube.com/vi/C4DPcsnVxHU/hqdefault.jpg"
             alt="YouTube video thumbnail – Bosch 3D Perception (LiDAR)">
        <span class="yt-play">▶</span>
      </a>
    </figure>
  </div>
</section>

<!-- Bosch – LiDAR Software -->
<section class="project-split" aria-labelledby="bosch-lidar-title">
  <div class="split-left">
    <h3 id="bosch-lidar-title">LiDAR Software Developer</h3>
    <p style="font-size:0.9rem; color:#666; margin:0.3rem 0 0.8rem;">
      Bosch • Abstatt, Germany • Jun 2016 – Mar 2017
    </p>
    <ul>
      <li>Integrated LiDAR sensors into the autonomous driving software stack.</li>
      <li>Implemented calibration pipelines to ensure accuracy over time.</li>
      <li>Developed decoders for multiple LiDAR sensor types.</li>
      <li>Contributed LiDAR features to a Kalman filter–based sensor fusion system.</li>
    </ul>
  </div>
</section>


    <!-- Patents & Links -->
    <section id="patents" aria-labelledby="patents-title">
      <h2 id="patents-title" class="section-heading">Patents</h2>
      <div class="section-card">
        <ul style="list-style:none; padding:0; margin:0; line-height:1.8;">
          <li>💡 <a href="https://patents.google.com/patent/US20250021879A1/en" target="_blank" rel="noopener"><strong>Computer-Implemented Method and System for Training a Planning Model</strong></a> (2025)</li>
          <li>💡 <a href="https://patents.google.com/patent/US20240278808A1/en" target="_blank" rel="noopener"><strong>Method for Behavior Planning of an Ego Vehicle as Part of a Traffic Scene</strong></a> (2024)</li>
        </ul>

      </div>
    </section>

    <!-- Contact / Personal touch -->
    <section id="contact" aria-labelledby="contact-title">
      <h2 id="contact-title" class="section-heading">Contact</h2>
      <div class="section-card">
        <p>
          I welcome opportunities for collaborative research in the areas of planning, world models, diffusion policies, and sim-to-real.
          Reach out via <a href="https://www.linkedin.com/in/juergen-mathes-44b389131/" target="_blank" rel="noopener">LinkedIn</a>.
        </p>
      </div>
    </section>

    <footer>
      <p>© Jürgen Mathes • Last updated: 13 September 2025 • <a href="#top">Back to top</a></p>
    </footer>
  </div>
</body>
</html>
